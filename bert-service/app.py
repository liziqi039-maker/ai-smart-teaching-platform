from flask import Flask, request, jsonify
import torch
from transformers import BertTokenizer, BertModel
from sklearn.metrics.pairwise import cosine_similarity
import os

app = Flask(__name__)

# åŠ è½½BERTæ¨¡å‹
print("æ­£åœ¨åŠ è½½BERTä¸­æ–‡è¯­ä¹‰æ¨¡å‹...")
tokenizer = None
model = None

try:
    tokenizer = BertTokenizer.from_pretrained("bert-base-chinese")
    model = BertModel.from_pretrained("bert-base-chinese")
    print("âœ… BERTæ¨¡å‹åŠ è½½å®Œæˆï¼")
except Exception as e:
    print(f"âš ï¸ æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{e}")
    print("è¯·ç¡®ä¿ç½‘ç»œæ­£å¸¸ï¼Œé¦–æ¬¡åŠ è½½éœ€è¦ä¸‹è½½æ¨¡å‹æ–‡ä»¶")

def get_text_embedding(text):
    """å°†æ–‡æœ¬è½¬ä¸ºBERTè¯­ä¹‰å‘é‡"""
    if not tokenizer or not model:
        return None
    
    try:
        inputs = tokenizer(
            text, return_tensors="pt", padding=True, truncation=True, max_length=512
        )
        with torch.no_grad():
            outputs = model(**inputs)
        return outputs.last_hidden_state[:, 0, :].numpy()
    except Exception as e:
        print(f"ç”Ÿæˆæ–‡æœ¬å‘é‡å¤±è´¥: {e}")
        return None

def calculate_similarity(text1, text2):
    """è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„è¯­ä¹‰ç›¸ä¼¼åº¦"""
    try:
        emb1 = get_text_embedding(text1)
        emb2 = get_text_embedding(text2)
        
        if emb1 is None or emb2 is None:
            return None
        
        return cosine_similarity(emb1, emb2)[0][0]
    except Exception as e:
        print(f"è®¡ç®—ç›¸ä¼¼åº¦å¤±è´¥: {e}")
        return None

@app.route('/api/similarity', methods=['POST'])
def api_calculate_similarity():
    """è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„è¯­ä¹‰ç›¸ä¼¼åº¦API"""
    try:
        data = request.get_json()
        text1 = data.get('text1', '')
        text2 = data.get('text2', '')
        
        if not text1 or not text2:
            return jsonify({
                'success': False,
                'message': 'éœ€è¦ä¸¤ä¸ªæ–‡æœ¬å‚æ•°'
            }), 400
        
        if not tokenizer or not model:
            return jsonify({
                'success': False,
                'message': 'AIæ¨¡å‹æœªåŠ è½½'
            }), 503
        
        similarity = calculate_similarity(text1, text2)
        
        if similarity is None:
            return jsonify({
                'success': False,
                'message': 'è®¡ç®—å¤±è´¥'
            }), 500
        
        return jsonify({
            'success': True,
            'similarity': float(similarity),
            'score': round(similarity * 100, 2),
            'analysis': get_analysis_by_score(similarity * 100)
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è®¡ç®—å¤±è´¥: {str(e)}'
        }), 500

def get_analysis_by_score(score):
    """æ ¹æ®åˆ†æ•°è¿”å›åˆ†æç»“æœ"""
    if score >= 90:
        return "ç­”æ¡ˆéå¸¸å‡†ç¡®ï¼Œå®Œå…¨ç†è§£äº†é—®é¢˜æ ¸å¿ƒ"
    elif score >= 80:
        return "ç­”æ¡ˆåŸºæœ¬æ­£ç¡®ï¼Œæ¶µç›–äº†ä¸»è¦çŸ¥è¯†ç‚¹"
    elif score >= 70:
        return "ç­”æ¡ˆéƒ¨åˆ†æ­£ç¡®ï¼Œéœ€è¦è¡¥å……ç»†èŠ‚"
    elif score >= 60:
        return "ç­”æ¡ˆæ–¹å‘æ­£ç¡®ï¼Œä½†è¡¨è¿°ä¸å¤Ÿå‡†ç¡®"
    else:
        return "ç­”æ¡ˆéœ€è¦æ”¹è¿›ï¼Œå»ºè®®é‡æ–°å­¦ä¹ ç›¸å…³çŸ¥è¯†ç‚¹"

@app.route('/api/batch-similarity', methods=['POST'])
def batch_calculate_similarity():
    """æ‰¹é‡è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦"""
    try:
        data = request.get_json()
        student_answers = data.get('student_answers', [])
        reference_answers = data.get('reference_answers', [])
        
        if len(student_answers) != len(reference_answers):
            return jsonify({
                'success': False,
                'message': 'å­¦ç”Ÿç­”æ¡ˆå’Œå‚è€ƒç­”æ¡ˆæ•°é‡ä¸åŒ¹é…'
            }), 400
        
        if not tokenizer or not model:
            return jsonify({
                'success': False,
                'message': 'AIæ¨¡å‹æœªåŠ è½½'
            }), 503
        
        results = []
        for i in range(len(student_answers)):
            similarity = calculate_similarity(student_answers[i], reference_answers[i])
            if similarity is not None:
                score = round(similarity * 100, 2)
                results.append({
                    'index': i,
                    'similarity': float(similarity),
                    'score': score,
                    'analysis': get_analysis_by_score(score)
                })
            else:
                results.append({
                    'index': i,
                    'similarity': 0,
                    'score': 0,
                    'analysis': 'è®¡ç®—å¤±è´¥'
                })
        
        return jsonify({
            'success': True,
            'results': results,
            'average_score': round(sum(r['score'] for r in results) / len(results), 2) if results else 0
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'æ‰¹é‡è®¡ç®—å¤±è´¥: {str(e)}'
        }), 500

@app.route('/health', methods=['GET'])
def health():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        'success': True,
        'service': 'BERTè¯­ä¹‰åˆ†ææœåŠ¡',
        'model_loaded': tokenizer is not None and model is not None,
        'status': 'running'
    })

@app.route('/')
def index():
    """é¦–é¡µ"""
    return jsonify({
        'service': 'BERTè¯­ä¹‰åˆ†ææœåŠ¡',
        'version': '1.0.0',
        'endpoints': {
            'similarity': '/api/similarity',
            'batch_similarity': '/api/batch-similarity',
            'health': '/health'
        }
    })

if __name__ == '__main__':
    port = int(os.environ.get('BERT_SERVICE_PORT', 5001))
    host = os.environ.get('BERT_SERVICE_HOST', '0.0.0.0')
    print(f"ğŸš€ BERTè¯­ä¹‰æœåŠ¡å¯åŠ¨åœ¨ http://{host}:{port}")
    app.run(host=host, port=port, debug=True)